{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)Explain dimension reduction in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In certain cases the data will be huge which makes the model less accurate and increases the time complexity.In machine learning algorithm first we need to process the data to meaningful one for a better predictive model.Some times high dimensionality becomes a great problem.  Dimensionality reduction can be used to overcome curse of dimensionality. The curse of dimensionality refers to various phenomena that arise when analyzing and organizing data in high-dimensional spaces that do not occur in low-dimensional settings such as the three-dimensional physical space of everyday experience. \n",
    "Dimension reduction, is the transformation of data from a high-dimensional space into a low-dimensional space \n",
    "so that the low-dimensional representation retains some meaningful properties of the original data. Basically, in some situation input variables will be more than the number of rows or in situation were multiple columns  give same meaning or influence  to the target variable in such situation we will go for dimension reduction. That is basically we need to get the proper data \n",
    "before training the model for the best fit. Principal Component Analysis is one such technique for dimensionality reduction. Principal Component Analysis (PCA) is used to explain the variance-covariance structure of a set of variables through linear combinations.\n",
    "\n",
    "Components of dimensionality reduction are\n",
    "\n",
    "• feature engineering\n",
    "\n",
    "• feature selection\n",
    "\n",
    "Methods of dimensionality reduction are\n",
    "\n",
    "• Principal Component Analysis\n",
    "\n",
    "• Linear Discriminant Analysis\n",
    "\n",
    "Dimensionality reduction technique:\n",
    "\n",
    "• Removes correlated features\n",
    "\n",
    "• Improves algorithm performance\n",
    "\n",
    "• Reduce overfitting\n",
    "\n",
    "• Improves Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)How can you handle duplicate values in a dataset for a variable in Python using pandas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #reading the dataset\n",
    "df = pd.read_csv('file.csv')\n",
    "\n",
    "#checks if the whole row appears elsewhere with the same values in each column \n",
    "df.duplicated()\n",
    "\n",
    "#checks if there are duplicate values in a particular column of the DataFrame\n",
    "df.duplicated('Column_name')\n",
    "\n",
    "#drop duplicate records \n",
    "df.drop_duplicates()\n",
    "\n",
    "#drop duplicates just from one column.\n",
    "df.drop_duplicates(['column_name'])\n",
    "\n",
    "\n",
    "\n",
    "df.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "#subset:if a column is passed only that will be considered, default is None\n",
    "#keep\n",
    "#keep='first': to keep the first argument from the duplicates \n",
    "#keep='last' : to keep the last argument from the duplicates \n",
    "#keep=False : to drop all the duplicates altogether \n",
    "#parameter inplace: If True, performs operation inplace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
